<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-11-21 Wed 09:02 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="generator" content="Org mode" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org10a4a4d">1. Multivariable Linear Regression (Python)</a>
<ul>
<li><a href="#org984c1e7">1.1. Introduction</a></li>
<li><a href="#orgd92dccf">1.2. Example</a>
<ul>
<li><a href="#orgd5e5677">1.2.1. Dataset and goal</a></li>
<li><a href="#orge726c3a">1.2.2. Main.py</a></li>
<li><a href="#org728576d">1.2.3. output</a></li>
</ul>
</li>
<li><a href="#org6ae99b0">1.3. Things to add or improve</a>
<ul>
<li><a href="#org42dcfd7">1.3.1. Command line interaction</a></li>
<li><a href="#orge1fc266">1.3.2. Add the option for 3d plotting</a></li>
<li><a href="#orgd0a8ba0">1.3.3. Logistic regression</a></li>
<li><a href="#org82dbf2b">1.3.4. Error handling for incorrect inputs</a></li>
<li><a href="#org20952b9">1.3.5. Better CSV reading</a></li>
<li><a href="#org665a8b7">1.3.6. Tidy up output formatting</a></li>
</ul>
</li>
<li><a href="#org32cfa3a">1.4. Files</a>
<ul>
<li><a href="#orga757c50">1.4.1. <code>main.py</code></a></li>
<li><a href="#orge2ecc19">1.4.2. <code>mvr.py</code></a></li>
<li><a href="#orge0e47ff">1.4.3. <code>mvr_calc.py</code></a></li>
<li><a href="#orgbb4eaf1">1.4.4. antelope data</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org10a4a4d" class="outline-2">
<h2 id="org10a4a4d"><span class="section-number-2">1</span> Multivariable Linear Regression (Python)</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org984c1e7" class="outline-3">
<h3 id="org984c1e7"><span class="section-number-3">1.1</span> Introduction</h3>
<div class="outline-text-3" id="text-1-1">
<p>
A small project to take in a set of data points (x<sub>0</sub>, x<sub>1</sub>, &#x2026;,x<sub>n</sub>, y) and to be able to predict y values for some new values (x<sub>0</sub>',x<sub>1</sub>',&#x2026;,x<sub>n</sub>').
Also computing some additional data such as the coefficient of determination (R<sup>2</sup>) to see how well the predictor variables model y.
</p>
</div>
</div>
<div id="outline-container-orgd92dccf" class="outline-3">
<h3 id="orgd92dccf"><span class="section-number-3">1.2</span> Example</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-orgd5e5677" class="outline-4">
<h4 id="orgd5e5677"><span class="section-number-4">1.2.1</span> Dataset and goal</h4>
<div class="outline-text-4" id="text-1-2-1">
</div>
<ol class="org-ol">
<li><a id="orgba82a78"></a>Dataset<br />
<div class="outline-text-5" id="text-1-2-1-1">
<p>
The example data has been adapted from the Thunder Basin Antelope study found <a href="https://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/frames/frame.html">online here</a>.
The data contains four variables (each corresponding to a year), the first being the spring fawn count(/100),
the second being annual precipitation (inches),
the third being the winter severity index (1=mild, 5=severe),
and the fourth variable (which is the one which will act as the dependent variable y) is the size of the adult antelope population(/100).
</p>
</div>
</li>
<li><a id="org1128760"></a>Goal<br />
<div class="outline-text-5" id="text-1-2-1-2">
<p>
So the goal is to determine if the first three variables are good predictors of the adult antelope population size.
And if they are, to make predictions of adult antelope population based on new data that only contains the first three variables (spring fawn count, annual precipitation and winter severity).
</p>
</div>
</li>
</ol>
</div>
<div id="outline-container-orge726c3a" class="outline-4">
<h4 id="orge726c3a"><span class="section-number-4">1.2.2</span> Main.py</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
The main file handles the data acquisition from the csv files, and sends it to the MultivariableRegression class.
There is the option to add a file to process a list of prediction data and whether to plot data.
</p>
<div class="org-src-container">
<pre class="src src-python"><span style="color: #00af00;">import</span> numpy <span style="color: #00af00;">as</span> np
<span style="color: #00af00;">import</span> csv
<span style="color: #00af00;">import</span> mvr


<span style="color: #00af00;">class</span> <span style="color: #18b2b2;">Main</span>:

    <span style="color: #ff8700;">filename</span>  = <span style="color: #ff1f8b;">"antelopestudy.csv"</span>
    <span style="color: #ff8700;">predict</span>   = <span style="color: #ff1f8b;">"antelope_predict.csv"</span>
    <span style="color: #ff8700;">delimiter</span> = <span style="color: #ff1f8b;">','</span>

    <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">Load CSV headers only</span>
    <span style="color: #00af00;">with</span> <span style="color: #b218b2;">open</span>(filename) <span style="color: #00af00;">as</span> <span style="color: #b218b2;">file</span>:
        <span style="color: #ff8700;">reader</span> = csv.reader(<span style="color: #b218b2;">file</span>)
        <span style="color: #ff8700;">headers</span> = <span style="color: #b218b2;">next</span>(reader)

    <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">Load remaining CSV data</span>
    <span style="color: #ff8700;">data</span> = np.loadtxt(filename, delimiter=delimiter, skiprows=1)
    <span style="color: #ff8700;">prediction_data</span> = np.loadtxt(predict, delimiter=delimiter, skiprows=1)

    <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">Perform the regression</span>
    <span style="color: #ff8700;">r</span> = mvr.MultiVariableRegression(data, headers, estimates=prediction_data)
    r.plotData()
</pre>
</div>
</div>
</div>

<div id="outline-container-org728576d" class="outline-4">
<h4 id="org728576d"><span class="section-number-4">1.2.3</span> output</h4>
<div class="outline-text-4" id="text-1-2-3">
</div>
<ol class="org-ol">
<li><a id="orge473dc8"></a>results<br />
<ol class="org-ol">
<li><a id="orgf5ebe80"></a>txt output<br />
<div class="outline-text-6" id="text-1-2-3-1-1">
<div class="org-src-container">
<pre class="src src-txt">Running Analysis of Variance with given significance:0.95
Null hypothesis: A_0...A_n are all 0
Null hypotehesis rejected 6.59 &lt; 27.1
At least one A_x is not 0 with certainty 0.95
Null hypotehesis rejected 6.59 &lt; 11.6
A_0 is not 0 with certainty 0.95
Null hpothesis accepted6.59 &gt; 2.29
A_1 is 0 with certainty 0.95
Null hpothesis accepted6.59 &gt; 5.4
A_2 is 0 with certainty 0.95
For predictor variables: (0,): regression = [1.77142829 3.97714348]R^2 = 0.8615637849525227
For predictor variables: (1,): regression = [ 0.78979077 -1.05710652]R^2 = 0.7837637022913508
For predictor variables: (2,): regression = [-0.72183902 10.52528711]R^2 = 0.6494867453327626
For predictor variables: (0, 1): regression = [1.35202677 0.21051042 2.50211306]R^2 = 0.8457378818812388
For predictor variables: (0, 2): regression = [ 1.33311064 -0.27133953  5.86399668]R^2 = 0.89672011835548
For predictor variables: (1, 2): regression = [ 0.69234295 -0.10668834  0.42265053]R^2 = 0.7445482721426719
For predictor variables: (0, 1, 2): regression = [ 2.19667031 -0.70400663 -0.60502981 13.11734799]R^2 = 0.917920937434756
x_n [ 2.5 14.   3. ] y_hat 6.94 ci 2.67 pi 2.8 with confidence 0.95
</pre>
</div>
</div>
</li>
<li><a id="org994203b"></a>figure output<br />
<div class="outline-text-6" id="text-1-2-3-1-2">
<p>
<a href="Figure_0.png">Figure 0</a>
</p>

<p>
<a href="Figure_1.png">Figure 1</a>
</p>

<p>
<a href="Figure_2.png">Figure 2</a>
</p>
</div>
</li>
</ol>
</li>

<li><a id="orgefa0dd0"></a>analysis<br />
<div class="outline-text-5" id="text-1-2-3-2">
<p>
An analysis of variance test is run on the data. The analysis is run with a null hypothesis to check whether the population regression coefficients (A<sub>0</sub>, A<sub>1</sub>, A<sub>2</sub>) are 0.
From the output, A<sub>0</sub> (spring fawn count) is found to be a good predictor of the dependent variable.
However the null hypothesis is accepted for both A<sub>1</sub> (annual precipitation) and A<sub>2</sub> (winter severity index),
meaning we cannot say with 95% confidence that annual precipitation and the winter severity affects the adult antelope population.
</p>

<p>
Note: with significance of 95%, there is a 5% chance we reject the null hypothesis when it is true.
</p>

<p>
Additionally you can see the coefficient of determination (R<sup>2</sup>) is highest for the 0th predictor (spring fawn count).
Based on this information, more data needs to be gathered to see if annual precipitation and winter severity can be a good indicator of population size.
Right now with the curren data, it is not a reliable indicator.
</p>

<p>
The regression can be run again, using only the spring fawn count as the only independent variable.
</p>
</div>
</li>

<li><a id="org15cb417"></a>Results (using only spring fawn count as the independent variable)<br />
<ol class="org-ol">
<li><a id="orge4a2447"></a>Update dataset<br />
<div class="outline-text-6" id="text-1-2-3-3-1">
<p>
It is possible to quickly make a new dataset by making use of cut, to select columns 1 and 4.
Then the main file gets updated to handle the new file, and the prediction file.
</p>
<div class="org-src-container">
<pre class="src src-sh">cat antelopestudy.csv | cut -d<span style="color: #ff1f8b;">","</span> -f1,4 &gt; antelopestudy_2.csv 
</pre>
</div>
</div>
</li>
<li><a id="org3dac46c"></a>Output<br />
<div class="outline-text-6" id="text-1-2-3-3-2">
<div class="org-src-container">
<pre class="src src-txt">Running Analysis of Variance with given significance:0.95
Null hypothesis: A_0...A_n are all 0
Null hypotehesis rejected 5.99 &lt; 44.6
Atleast one A_x is not 0 with certainty 0.95
For predictor variables: (0,): regression = [1.77142829 3.97714348]R^2 = 0.8615637849525227
x_n [2.5] y_hat 8.41 ci 0.347 pi 1.04 with confidence 0.95
</pre>
</div>
<p>
<a href="Figure_3.png">Figure 3</a>
</p>
</div>
</li>

<li><a id="org2435760"></a>Prediction<br />
<div class="outline-text-6" id="text-1-2-3-3-3">
<p>
The output regression equation is 1.77a + 3.98. So for some given fawn count, an estimate can be given of the adult antelope count.
</p>

<p>
So given the fact that the spring fawn count is 250, an estimate is given of 841 adult antelopes.
If there were many fawn counts of 250, the expected mean adult antelopes is expected to fall within the predicted (841) plus or minus the confidence interval (0.347) which represents a hundered.
So with 0.95 confidence and spring fawn count of 250, the mean adult antelopes is expected to fall within 841-35 and 841+35.
</p>

<p>
With observed readings (with 0.95 confidence) falling in 841-104 to 841+104
</p>
</div>
</li>
</ol>
</li>
</ol>
</div>
</div>


<div id="outline-container-org6ae99b0" class="outline-3">
<h3 id="org6ae99b0"><span class="section-number-3">1.3</span> Things to add or improve</h3>
<div class="outline-text-3" id="text-1-3">
</div>
<div id="outline-container-org42dcfd7" class="outline-4">
<h4 id="org42dcfd7"><span class="section-number-4">1.3.1</span> Command line interaction</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
Could add some more command line interaction, taking file names and processing the sys.argv values.
</p>
</div>
</div>
<div id="outline-container-orge1fc266" class="outline-4">
<h4 id="orge1fc266"><span class="section-number-4">1.3.2</span> Add the option for 3d plotting</h4>
<div class="outline-text-4" id="text-1-3-2">
<p>
For data with two predictor variables, it could be nice to have a 3D graph to display the regression line.
</p>
</div>
</div>
<div id="outline-container-orgd0a8ba0" class="outline-4">
<h4 id="orgd0a8ba0"><span class="section-number-4">1.3.3</span> Logistic regression</h4>
<div class="outline-text-4" id="text-1-3-3">
<p>
Add the ability to do logistic regression.
</p>
</div>
</div>
<div id="outline-container-org82dbf2b" class="outline-4">
<h4 id="org82dbf2b"><span class="section-number-4">1.3.4</span> Error handling for incorrect inputs</h4>
<div class="outline-text-4" id="text-1-3-4">
<p>
Currently, the program will just exit poorly if the input data is not of the expected format.
</p>
</div>
</div>
<div id="outline-container-org20952b9" class="outline-4">
<h4 id="org20952b9"><span class="section-number-4">1.3.5</span> Better CSV reading</h4>
<div class="outline-text-4" id="text-1-3-5">
<p>
Currently the CSV reading is not ideal, as both numpy and csv reade4r is used to open the csv, numpy for the data and csv reader for the header information.
</p>
</div>
</div>
<div id="outline-container-org665a8b7" class="outline-4">
<h4 id="org665a8b7"><span class="section-number-4">1.3.6</span> Tidy up output formatting</h4>
<div class="outline-text-4" id="text-1-3-6">
<p>
Output formatting can either be made to output as a table format.
</p>
</div>
</div>
</div>

<div id="outline-container-org32cfa3a" class="outline-3">
<h3 id="org32cfa3a"><span class="section-number-3">1.4</span> Files</h3>
<div class="outline-text-3" id="text-1-4">
<p>
You can look at the code of the program here:
</p>
</div>

<div id="outline-container-orga757c50" class="outline-4">
<h4 id="orga757c50"><span class="section-number-4">1.4.1</span> <code>main.py</code></h4>
<div class="outline-text-4" id="text-1-4-1">
<p>
<a href="main.py"><code>main.py</code></a> (Loads the CSV data and runs the regression)
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #00af00;">import</span> numpy <span style="color: #00af00;">as</span> np
<span style="color: #00af00;">import</span> csv
<span style="color: #00af00;">import</span> mvr


<span style="color: #00af00;">class</span> <span style="color: #18b2b2;">Main</span>:

    <span style="color: #ff8700;">filename</span>  = <span style="color: #ff1f8b;">"antelopestudy.csv"</span>
    <span style="color: #ff8700;">predict</span>   = <span style="color: #ff1f8b;">"antelope_predict.csv"</span>
    <span style="color: #ff8700;">delimiter</span> = <span style="color: #ff1f8b;">','</span>

    <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">Load CSV headers only</span>
    <span style="color: #00af00;">with</span> <span style="color: #b218b2;">open</span>(filename) <span style="color: #00af00;">as</span> <span style="color: #b218b2;">file</span>:
        <span style="color: #ff8700;">reader</span> = csv.reader(<span style="color: #b218b2;">file</span>)
        <span style="color: #ff8700;">headers</span> = <span style="color: #b218b2;">next</span>(reader)

    <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">Load remaining CSV data</span>
    <span style="color: #ff8700;">data</span> = np.loadtxt(filename, delimiter=delimiter, skiprows=1)
    <span style="color: #ff8700;">prediction_data</span> = np.loadtxt(predict, delimiter=delimiter, skiprows=1)

    <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">Perform the regression</span>
    <span style="color: #ff8700;">r</span> = mvr.MultiVariableRegression(data, headers, estimates=prediction_data)
    r.plotData()
</pre>
</div>
</div>
</div>

<div id="outline-container-orge2ecc19" class="outline-4">
<h4 id="orge2ecc19"><span class="section-number-4">1.4.2</span> <code>mvr.py</code></h4>
<div class="outline-text-4" id="text-1-4-2">
<p>
<a href="mvr.py"><code>mvr.py</code></a> (Handles the multivariable regression data)
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #00af00;">import</span> numpy <span style="color: #00af00;">as</span> np
<span style="color: #00af00;">import</span> matplotlib.pyplot <span style="color: #00af00;">as</span> plt
<span style="color: #00af00;">import</span> itertools

<span style="color: #00af00;">import</span> mvr_calc

<span style="color: #00af00;">class</span> <span style="color: #18b2b2;">MultiVariableRegression</span>:
    <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">    Class to manage the multivariable regression, holding a data class,</span>
<span style="color: #cc0000;">    which has it's own calculation class to handle regression calculations.</span>
<span style="color: #cc0000;">    """</span>

    <span style="color: #00af00;">class</span> <span style="color: #18b2b2;">Data</span>:
        <span style="color: #cc0000;">"""Holds the raw numerical data for the regression calculations"""</span>
        <span style="color: #00af00;">def</span> <span style="color: #ef2929;">sanityCheck</span>(<span style="color: #00af00;">self</span>):
            <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">            Test statistics rely on the degrees of freedom being</span>
<span style="color: #cc0000;">            greater than 0, Having more data than the number of</span>
<span style="color: #cc0000;">            variable predictors (x.. x_n) by atleast 2 will satisfy</span>
<span style="color: #cc0000;">            the sanity check.</span>
<span style="color: #cc0000;">            """</span>
            <span style="color: #00af00;">if</span> <span style="color: #00af00;">self</span>.df &gt; 0:
                <span style="color: #00af00;">self</span>.sane = <span style="color: #1f5bff;">True</span>

        <span style="color: #00af00;">def</span> <span style="color: #ef2929;">populateMetaData</span>(<span style="color: #00af00;">self</span>):
            <span style="color: #00af00;">self</span>.ndim  = <span style="color: #00af00;">self</span>.c.getMatrixWidth(<span style="color: #00af00;">self</span>.x)
            <span style="color: #00af00;">self</span>.ndata = <span style="color: #00af00;">self</span>.y.size
            <span style="color: #00af00;">self</span>.df    = <span style="color: #00af00;">self</span>.ndata - <span style="color: #00af00;">self</span>.ndim - 1

            <span style="color: #00af00;">self</span>.x_matrix = <span style="color: #00af00;">self</span>.c.addOnesToData(<span style="color: #00af00;">self</span>.x, <span style="color: #00af00;">self</span>.ndata, <span style="color: #00af00;">self</span>.ndim)

        <span style="color: #00af00;">def</span> <span style="color: #ef2929;">populateVariance</span>(<span style="color: #00af00;">self</span>):
            <span style="color: #00af00;">self</span>.y_bar = <span style="color: #00af00;">self</span>.c.calcAverage(<span style="color: #00af00;">self</span>.y)
            <span style="color: #00af00;">self</span>.x_bar = <span style="color: #00af00;">self</span>.c.calcAverage(<span style="color: #00af00;">self</span>.x)

            <span style="color: #00af00;">self</span>.y_variance = <span style="color: #00af00;">self</span>.c.calcVariance(<span style="color: #00af00;">self</span>.y,<span style="color: #00af00;">self</span>.y_bar)
            <span style="color: #00af00;">self</span>.x_variance = <span style="color: #00af00;">self</span>.c.calcVariance(<span style="color: #00af00;">self</span>.x,<span style="color: #00af00;">self</span>.x_bar).reshape(
                <span style="color: #00af00;">self</span>.ndata, <span style="color: #00af00;">self</span>.ndim)

            <span style="color: #00af00;">self</span>.y_variance_sq = <span style="color: #00af00;">self</span>.c.calcSumProduct(
                <span style="color: #00af00;">self</span>.y_variance,<span style="color: #00af00;">self</span>.y_variance)

            <span style="color: #00af00;">self</span>.x_variance_sq = np.zeros(<span style="color: #00af00;">self</span>.ndim)
            <span style="color: #00af00;">self</span>.x_y_variance  = np.zeros(<span style="color: #00af00;">self</span>.ndim)

            <span style="color: #00af00;">for</span> n <span style="color: #00af00;">in</span> <span style="color: #b218b2;">range</span>(0, <span style="color: #00af00;">self</span>.ndim):
                <span style="color: #ff8700;">x_var</span> = <span style="color: #00af00;">self</span>.x_variance[:,n]
                <span style="color: #00af00;">self</span>.x_variance_sq[n] = <span style="color: #00af00;">self</span>.c.calcSumProduct(
                    x_var, x_var)
                <span style="color: #00af00;">self</span>.x_y_variance[n]  = <span style="color: #00af00;">self</span>.c.calcSumProduct(
                    x_var, <span style="color: #00af00;">self</span>.y_variance)

        <span style="color: #00af00;">def</span> <span style="color: #ef2929;">populateCorrelation</span>(<span style="color: #00af00;">self</span>):
            <span style="color: #00af00;">self</span>.correlation = <span style="color: #00af00;">self</span>.c.calcCorrelation(
                <span style="color: #00af00;">self</span>.ndim,
                <span style="color: #00af00;">self</span>.x_y_variance,
                <span style="color: #00af00;">self</span>.x_variance_sq,
                <span style="color: #00af00;">self</span>.y_variance_sq)

        <span style="color: #00af00;">def</span> <span style="color: #ef2929;">populateRegression</span>(<span style="color: #00af00;">self</span>):
            <span style="color: #00af00;">self</span>.s_matrix = <span style="color: #00af00;">self</span>.c.findSMatrix(<span style="color: #00af00;">self</span>.x_matrix)
            <span style="color: #00af00;">self</span>.regression = <span style="color: #00af00;">self</span>.c.calcRegression(
                <span style="color: #00af00;">self</span>.s_matrix, <span style="color: #00af00;">self</span>.x_matrix, <span style="color: #00af00;">self</span>.y)

        <span style="color: #00af00;">def</span> <span style="color: #ef2929;">populateEstimationData</span>(<span style="color: #00af00;">self</span>):
            <span style="color: #00af00;">self</span>.y_hat   = np.dot(<span style="color: #00af00;">self</span>.x_matrix, <span style="color: #00af00;">self</span>.regression)
            <span style="color: #00af00;">self</span>.y_error = <span style="color: #00af00;">self</span>.y - <span style="color: #00af00;">self</span>.y_hat

            <span style="color: #00af00;">self</span>.sum_errors_sq = <span style="color: #00af00;">self</span>.c.calcSumProduct(
                <span style="color: #00af00;">self</span>.y_error, <span style="color: #00af00;">self</span>.y_error)

            <span style="color: #00af00;">self</span>.adjusted_R_sq = <span style="color: #00af00;">self</span>.c.findAdjustedRSquared(
                <span style="color: #00af00;">self</span>.sum_errors_sq, <span style="color: #00af00;">self</span>.y_variance_sq, <span style="color: #00af00;">self</span>.ndata, <span style="color: #00af00;">self</span>.df)

        <span style="color: #00af00;">def</span> <span style="color: #ef2929;">__init__</span>(<span style="color: #00af00;">self</span>,x,y,c):
            <span style="color: #00af00;">self</span>.x = x
            <span style="color: #00af00;">self</span>.y = y
            <span style="color: #00af00;">self</span>.c = c
            <span style="color: #00af00;">self</span>.populateMetaData()
            <span style="color: #00af00;">self</span>.sanityCheck()
            <span style="color: #00af00;">if</span> <span style="color: #00af00;">self</span>.sane:
                <span style="color: #00af00;">self</span>.populateVariance()
                <span style="color: #00af00;">self</span>.populateCorrelation()
                <span style="color: #00af00;">self</span>.populateRegression()
                <span style="color: #00af00;">self</span>.populateEstimationData()

    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">ANOVA</span>(<span style="color: #00af00;">self</span>,core_data,significance):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Run the analysis of variance test on the data. The analysis</span>
<span style="color: #cc0000;">        is run with a null hypothesis to check whether the population</span>
<span style="color: #cc0000;">        regression coefficients (A_0 ... A_n) are 0. Such that the data</span>
<span style="color: #cc0000;">        follows a normal distribution with mean B and standard deviation</span>
<span style="color: #cc0000;">        sigma. By rejecting the hypothesis, we can say with the given</span>
<span style="color: #cc0000;">        significance the x dimensions do affect the y data. And</span>
<span style="color: #cc0000;">        uses the F distribution to determine the critical value.</span>

<span style="color: #cc0000;">        Run once for All A_0,... A_n being 0, which can be rejected</span>
<span style="color: #cc0000;">        if any A is not 0. Then run for each A_x.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">print</span>(f<span style="color: #ff1f8b;">'Running Analysis of Variance with given significance:'</span>
              + f<span style="color: #ff1f8b;">'{significance}\nNull hypothesis: A_0...A_n are all 0'</span>)

        <span style="color: #ff8700;">test_statistic</span> = <span style="color: #00af00;">self</span>.c.calcTestStatisticAllX(
            core_data.y_variance_sq,
            core_data.sum_errors_sq,
            core_data.ndim,
            core_data.df)

        <span style="color: #ff8700;">critical_value</span> = core_data.c.findCriticalFValue(
            core_data.ndim,
            core_data.df,
            significance)

        <span style="color: #00af00;">if</span> critical_value &lt; test_statistic:
            <span style="color: #00af00;">print</span>(f<span style="color: #ff1f8b;">'Null hypotehesis rejected '</span>
                  + f<span style="color: #ff1f8b;">'{critical_value:.3} &lt; {test_statistic:.3}\n'</span>
                  + f<span style="color: #ff1f8b;">'At least one A_x is not 0 with certainty {significance}'</span>)
        <span style="color: #00af00;">else</span>:
            <span style="color: #00af00;">print</span>(f<span style="color: #ff1f8b;">'Null hpothesis accepted'</span>
                  + f<span style="color: #ff1f8b;">'{critical_value:.3} &gt; {test_statistic:.3}\n'</span>
                  + f<span style="color: #ff1f8b;">'All A_x are 0 with certainty {significance}'</span>)

        <span style="color: #00af00;">if</span> core_data.ndim &gt; 1:
            <span style="color: #00af00;">for</span> n <span style="color: #00af00;">in</span> <span style="color: #b218b2;">range</span>(0,core_data.ndim):
                <span style="color: #ff8700;">test_statistic</span> = <span style="color: #00af00;">self</span>.c.calcTestStatisticSingleX(
                    core_data.regression,
                    core_data.s_matrix,
                    core_data.sum_errors_sq,
                    n,
                    core_data.df)

                <span style="color: #ff8700;">critical_value</span> = core_data.c.findCriticalFValue(
                    core_data.ndim,
                    core_data.df,
                    significance)

                <span style="color: #00af00;">if</span> critical_value &lt; test_statistic:
                    <span style="color: #00af00;">print</span>(f<span style="color: #ff1f8b;">'Null hypotehesis rejected '</span>
                          + f<span style="color: #ff1f8b;">'{critical_value:.3} &lt; {test_statistic:.3}\n'</span>
                          + f<span style="color: #ff1f8b;">'A_{n} is not 0 with certainty {significance}'</span>)
                <span style="color: #00af00;">else</span>:
                    <span style="color: #00af00;">print</span>(f<span style="color: #ff1f8b;">'Null hpothesis accepted'</span>
                          + f<span style="color: #ff1f8b;">'{critical_value:.3} &gt; {test_statistic:.3}\n'</span>
                          + f<span style="color: #ff1f8b;">'A_{n} is 0 with certainty {significance}'</span>)


    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">roundRobin</span>(<span style="color: #00af00;">self</span>):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Calculate the adjusted R^2 value for all combinations of</span>
<span style="color: #cc0000;">        predictor variables, to determine which predictor variables</span>
<span style="color: #cc0000;">        are best suited to the regression.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">Starting with 1 predictor variable up to n variables</span>
        <span style="color: #00af00;">for</span> n <span style="color: #00af00;">in</span> <span style="color: #b218b2;">range</span>(0, <span style="color: #00af00;">self</span>.core_data.ndim):
            <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">Generate all combinations of predictor variables</span>
            <span style="color: #00af00;">for</span> i <span style="color: #00af00;">in</span> itertools.combinations(<span style="color: #b218b2;">range</span>(0, <span style="color: #00af00;">self</span>.core_data.ndim), n+1):
                <span style="color: #ff8700;">x</span> = <span style="color: #00af00;">self</span>.core_data.x[:,i]
                <span style="color: #ff8700;">sub_data</span> = <span style="color: #00af00;">self</span>.Data(x, <span style="color: #00af00;">self</span>.core_data.y, <span style="color: #00af00;">self</span>.c)

                <span style="color: #00af00;">print</span>(f<span style="color: #ff1f8b;">'For predictor variables: {i}'</span>
                      + f<span style="color: #ff1f8b;">': regression = {sub_data.regression}'</span>
                      + f<span style="color: #ff1f8b;">'R^2 = {sub_data.adjusted_R_sq}'</span>)


    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">plotData</span>(<span style="color: #00af00;">self</span>):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Plot each predictor variable against y, showing the correlation</span>
<span style="color: #cc0000;">        co-efficient for each variable. Additionally plots the regression</span>
<span style="color: #cc0000;">        line if there is only one predictor variable.</span>

<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">for</span> n <span style="color: #00af00;">in</span> <span style="color: #b218b2;">range</span>(0,<span style="color: #00af00;">self</span>.core_data.ndim):
            <span style="color: #b2b2b2; font-style: italic;">#</span><span style="color: #b2b2b2; font-style: italic;">plt.subplot(self.core_data.ndim, 1, n+1)</span>
            plt.figure(n)
            <span style="color: #ff8700;">x</span> = <span style="color: #00af00;">self</span>.core_data.x[:,n]
            <span style="color: #ff8700;">y</span> = <span style="color: #00af00;">self</span>.core_data.y
            plt.plot(x,y,<span style="color: #ff1f8b;">'o'</span>)

            plt.title(f<span style="color: #ff1f8b;">'Data correlation of:'</span>
                      + f<span style="color: #ff1f8b;">'{self.core_data.correlation[n]:.4}'</span>,
                      fontsize=20)
            plt.ylabel(f<span style="color: #ff1f8b;">'{self.headers[-1]}'</span>,fontsize=18)
            plt.xlabel(f<span style="color: #ff1f8b;">'{self.headers[n]}'</span>,fontsize=18)


        <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">Regression line only makes sense to plot with 1 predictor variable   </span>
        <span style="color: #00af00;">if</span> <span style="color: #00af00;">self</span>.core_data.ndim == 1:
            <span style="color: #ff8700;">a</span> = <span style="color: #00af00;">self</span>.core_data.regression[[n,<span style="color: #00af00;">self</span>.core_data.ndim]]
            <span style="color: #ff8700;">x_matrix</span>= <span style="color: #00af00;">self</span>.c.addOnesToData(x, x.size, 1)
            <span style="color: #ff8700;">y_hat</span> = np.dot(x_matrix, a)
            plt.plot(x, y_hat, <span style="color: #ff1f8b;">'-'</span>,label=<span style="color: #ff1f8b;">'Regression line'</span>)
            plt.legend()

        plt.show()

    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">estimateData</span>(<span style="color: #00af00;">self</span>):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        For a given input list of data, provide an estimate y value,</span>
<span style="color: #cc0000;">        along with a</span>
<span style="color: #cc0000;">        confidence interval: (the interval of the mean y value),</span>
<span style="color: #cc0000;">        prediction_interval: (the interval of predicted values).</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">if</span> <span style="color: #00af00;">self</span>.estimates <span style="color: #00af00;">is</span> <span style="color: #00af00;">not</span> <span style="color: #1f5bff;">None</span>:
            <span style="color: #ff8700;">n</span> = <span style="color: #00af00;">self</span>.estimates.size // <span style="color: #00af00;">self</span>.core_data.ndim
            <span style="color: #ff8700;">x</span> = <span style="color: #00af00;">self</span>.c.addOnesToData(<span style="color: #00af00;">self</span>.estimates, n, <span style="color: #00af00;">self</span>.core_data.ndim)

            <span style="color: #ff8700;">y_hat</span> = np.dot(x, <span style="color: #00af00;">self</span>.core_data.regression)

            <span style="color: #ff8700;">fval</span> = <span style="color: #00af00;">self</span>.c.findCriticalFValue(
                1, <span style="color: #00af00;">self</span>.core_data.df, <span style="color: #00af00;">self</span>.confidence)

            <span style="color: #00af00;">for</span> i <span style="color: #00af00;">in</span> <span style="color: #b218b2;">range</span>(0,n):
                <span style="color: #ff8700;">x_n</span> = x[i,:-1]

                <span style="color: #ff8700;">mahalanobis_distance</span> = <span style="color: #00af00;">self</span>.c.getMahalanobisDistance(x_n,
                    <span style="color: #00af00;">self</span>.core_data.x_bar,
                    <span style="color: #00af00;">self</span>.core_data.ndim,
                    <span style="color: #00af00;">self</span>.core_data.ndata,
                    <span style="color: #00af00;">self</span>.core_data.s_matrix)

                <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">fval, sum_errors_sq, df, ndata, mahalanobis_distance):</span>
                <span style="color: #ff8700;">confidence_interval</span> = <span style="color: #00af00;">self</span>.c.getConfidenceInterval(
                    <span style="color: #00af00;">self</span>.core_data.sum_errors_sq,
                    <span style="color: #00af00;">self</span>.core_data.df,
                    <span style="color: #00af00;">self</span>.core_data.ndata,
                    mahalanobis_distance,
                    fval)

                <span style="color: #ff8700;">prediction_interval</span> = <span style="color: #00af00;">self</span>.c.getPredictionInterval(
                    <span style="color: #00af00;">self</span>.core_data.sum_errors_sq,
                    <span style="color: #00af00;">self</span>.core_data.df,
                    <span style="color: #00af00;">self</span>.core_data.ndata,
                    mahalanobis_distance,
                    fval)

                <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">TODO: add table formatting before loop</span>
                <span style="color: #00af00;">print</span>(f<span style="color: #ff1f8b;">'x_n {x_n} y_hat {y_hat[i]:.3}'</span>
                      + f<span style="color: #ff1f8b;">' ci {confidence_interval[0,0]:.3}'</span>
                      + f<span style="color: #ff1f8b;">' pi {prediction_interval[0,0]:.3}'</span>
                      + f<span style="color: #ff1f8b;">' with confidence {self.confidence:.3}'</span>)


    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">populateData</span>(<span style="color: #00af00;">self</span>):
        <span style="color: #00af00;">if</span> <span style="color: #00af00;">not</span> <span style="color: #00af00;">self</span>.data_populated:
            <span style="color: #00af00;">self</span>.core_data = <span style="color: #00af00;">self</span>.Data(<span style="color: #00af00;">self</span>.data[:,0:-1],<span style="color: #00af00;">self</span>.data[:,-1],<span style="color: #00af00;">self</span>.c)
            <span style="color: #ff8700;">data_populated</span> = <span style="color: #1f5bff;">True</span>

    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">runAnalysisOfVariance</span>(<span style="color: #00af00;">self</span>, significance):
         <span style="color: #00af00;">self</span>.ANOVA(<span style="color: #00af00;">self</span>.core_data,significance)

    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">__init__</span>(<span style="color: #00af00;">self</span>, data, headers, confidence=0.95, estimates=<span style="color: #1f5bff;">None</span>):
        <span style="color: #00af00;">self</span>.data_populated = <span style="color: #1f5bff;">False</span>
        <span style="color: #00af00;">self</span>.data = data
        <span style="color: #00af00;">self</span>.confidence = confidence
        <span style="color: #00af00;">self</span>.c = mvr_calc.MVRCalculator()
        <span style="color: #00af00;">self</span>.headers = headers
        <span style="color: #00af00;">self</span>.estimates = estimates

        <span style="color: #00af00;">self</span>.populateData()

        <span style="color: #00af00;">self</span>.runAnalysisOfVariance(<span style="color: #00af00;">self</span>.confidence)
        <span style="color: #00af00;">self</span>.roundRobin()
        <span style="color: #00af00;">self</span>.estimateData()
</pre>
</div>
</div>
</div>
<div id="outline-container-orge0e47ff" class="outline-4">
<h4 id="orge0e47ff"><span class="section-number-4">1.4.3</span> <code>mvr_calc.py</code></h4>
<div class="outline-text-4" id="text-1-4-3">
<p>
<a href="mvr_calc.py"><code>mvr_calc.py</code></a> (Handles the calculations needed for multivariable regression)
</p>

<div class="org-src-container">
<pre class="src src-python"><span style="color: #00af00;">import</span> numpy <span style="color: #00af00;">as</span> np
<span style="color: #00af00;">from</span> scipy.stats <span style="color: #00af00;">import</span> f

<span style="color: #00af00;">class</span> <span style="color: #18b2b2;">MVRCalculator</span>:
    <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">    Class holds the calculations needed to perform the regression</span>
<span style="color: #cc0000;">    on some data. Used to seperate out the data and calculations.</span>
<span style="color: #cc0000;">    """</span>

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">searchValue</span>(f, target,
                    tolerance=0.000001, start=0, step_size=1, damping=0.5):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Finds x for a given target y, for a given linear function f(x).</span>
<span style="color: #cc0000;">        Works iteratively through values of x to find the target f(x)</span>
<span style="color: #cc0000;">        value, once the target is 'found', the step gets reversed</span>
<span style="color: #cc0000;">        and damped until the target is found within the given tolerance.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">def</span> <span style="color: #ef2929;">stepDirection</span>(increasing, lower):
            <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">            Finds whether x should increase of decrease,</span>
<span style="color: #cc0000;">            depending if the f(x) function is an increasing or decreasing</span>
<span style="color: #cc0000;">            function and if f(x_0) is lower than f(x_target)</span>
<span style="color: #cc0000;">            """</span>
            <span style="color: #00af00;">if</span> (increasing <span style="color: #00af00;">and</span> lower) <span style="color: #00af00;">or</span> (<span style="color: #00af00;">not</span> increasing <span style="color: #00af00;">and</span> <span style="color: #00af00;">not</span> lower):
                <span style="color: #00af00;">return</span>  1
            <span style="color: #00af00;">else</span>:
                <span style="color: #00af00;">return</span> -1

        <span style="color: #ff8700;">x</span>,<span style="color: #ff8700;">error</span>,<span style="color: #ff8700;">a0</span>,<span style="color: #ff8700;">a1</span> = start, tolerance+1, f(start), f(start+step_size)
        <span style="color: #ff8700;">increasing</span>, <span style="color: #ff8700;">start_lower</span> = a1 &gt; a0, a0 &lt; target

        <span style="color: #ff8700;">step_direction</span> = stepDirection(increasing, start_lower)
        <span style="color: #ff8700;">step</span> = step_direction * step_size

        <span style="color: #00af00;">while</span> <span style="color: #b218b2;">abs</span>(error) &gt; tolerance :
            <span style="color: #ff8700;">x</span> = x + step   
            <span style="color: #ff8700;">a</span> = f(x)

            <span style="color: #ff8700;">error</span> = target - a
            <span style="color: #ff8700;">lower</span> = error &gt; 0

            <span style="color: #ff8700;">new_step_direction</span> = stepDirection(increasing, lower)

            <span style="color: #b2b2b2; font-style: italic;"># </span><span style="color: #b2b2b2; font-style: italic;">If true, the target x is between f(x) and f(x-step)  </span>
            <span style="color: #00af00;">if</span> step_direction != new_step_direction:
                <span style="color: #ff8700;">step_size</span> = damping * step_size

            <span style="color: #ff8700;">step</span> = new_step_direction * step_size                
        <span style="color: #00af00;">return</span> x

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">addOnesToData</span>(x,ndata,ndim):
        <span style="color: #cc0000;">"""Adds a column of 1s to a given input vector or matrix"""</span>
        <span style="color: #b2b2b2; font-style: italic;">#</span><span style="color: #b2b2b2; font-style: italic;">if len(x.shape) == 1:</span>
        <span style="color: #b2b2b2; font-style: italic;">#    </span><span style="color: #b2b2b2; font-style: italic;">x = np.expand_dims(x, axis=0)</span>
        <span style="color: #ff8700;">x</span> = x.reshape(ndata,ndim)
        <span style="color: #00af00;">return</span> np.append(x,np.ones((ndata,1)), axis=1)

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">calcSumProduct</span>(vector1,vector2):
        <span style="color: #cc0000;">"""Returns the sum of the product of two vectors"""</span>
        <span style="color: #00af00;">return</span> np.<span style="color: #b218b2;">sum</span>(vector1 * vector2)

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">calcCorrelation</span>(ndim, x_y_variance, x_variance_sq, y_variance_sq):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Calculates the correlation between x and y data</span>
<span style="color: #cc0000;">        for each x dimension</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #ff8700;">coefficients</span> = np.zeros(ndim)
        <span style="color: #00af00;">for</span> n <span style="color: #00af00;">in</span> <span style="color: #b218b2;">range</span>(0,ndim):
            <span style="color: #ff8700;">coefficients</span>[n] = x_y_variance[n] / np.sqrt(
                x_variance_sq[n] * y_variance_sq)

        <span style="color: #00af00;">return</span> coefficients

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">calcRegression</span>(s_matrix,x_matrix,y):
        <span style="color: #cc0000;">"""Calculates the regression equation (a_0 -&gt; a_n + b)"""</span>
        <span style="color: #00af00;">return</span> np.dot(s_matrix, np.dot(x_matrix.T, y))

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">findSMatrix</span>(x_matrix):
        <span style="color: #00af00;">return</span> np.linalg.inv(np.dot(x_matrix.T,x_matrix))

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">findAdjustedRSquared</span>(sum_errors_sq,y_variance_sq,ndata,df):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Finds R^2, adjusted for the fact that normally R^2 will</span>
<span style="color: #cc0000;">        increase for added predictor variables regardless if the variable</span>
<span style="color: #cc0000;">        is a good predictor or not.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">return</span>  1 - ((sum_errors_sq / df) / (y_variance_sq / (ndata - 1)))

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">getMahalanobisDistance</span>(x_n, x_bar, ndim, ndata, s_matrix):
        <span style="color: #cc0000;">"""Get the mahalanobis distance of a given x_n"""</span>
        <span style="color: #ff8700;">x</span> = (x_n - x_bar).reshape(ndim,1)
        <span style="color: #00af00;">return</span> np.dot(x.T,np.dot(s_matrix[:-1,:-1],x)) * (ndata - 1)

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">findCriticalFValue</span>(ndim, df, significance):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Find F distribution values, used as critical values in</span>
<span style="color: #cc0000;">        Analysis of variance tests.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">return</span> MVRCalculator.searchValue(<span style="color: #00af00;">lambda</span> z: f.cdf(z,ndim,df),
                                            significance)

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">getConfidenceInterval</span>(
            sum_errors_sq, df, ndata, mahalanobis_distance, fval):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Interval range for the mean value of a predicted y, to account</span>
<span style="color: #cc0000;">        for the variance in the population data. With the confidence</span>
<span style="color: #cc0000;">        (e.g. 0.95) determined by fval.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">return</span> np.sqrt(fval
                       * (1/ndata + mahalanobis_distance / (ndata -1))
                       * (sum_errors_sq / df))

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">getPredictionInterval</span>(
            sum_errors_sq, df, ndata, mahalanobis_distance, fval):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Interval range to give a probable range of future values.</span>
<span style="color: #cc0000;">        This range will be higher than the confidence interval,</span>
<span style="color: #cc0000;">        to account for the fact that the mean predicted value</span>
<span style="color: #cc0000;">        can vary by the confidence value, and then additionally</span>
<span style="color: #cc0000;">        the value can vary from that mean.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">return</span> np.sqrt(fval
                       * (1 + 1/ndata + mahalanobis_distance / (ndata - 1))
                       * (sum_errors_sq / df))

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">getMatrixWidth</span>(v):
        <span style="color: #cc0000;">"""Function to find the width of a given numpy vector or matrix"""</span>
        <span style="color: #00af00;">if</span> <span style="color: #b218b2;">len</span>(np.shape(v)) &gt; 1:
            <span style="color: #00af00;">return</span> np.shape(v)[1]
        <span style="color: #00af00;">else</span>:
            <span style="color: #00af00;">return</span> 1

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">autoCorrelationTest</span>(y_error, sum_errors,sq):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Check for auto correlation in our y data using the</span>
<span style="color: #cc0000;">        Durbin-Watson statistic, a result lower than 1</span>
<span style="color: #cc0000;">        may indicate the presence of autocorrelation.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #ff8700;">residual</span> = y_error[1:] - y_error[:-1]
        <span style="color: #00af00;">return</span> (MVRCalculator.calcSumProduct(residual, residual)
                / sum_errors_sq)

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">calcAverage</span>(m):
        <span style="color: #00af00;">return</span> np.mean(m,axis=0)

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">calcVariance</span>(v,v_bar):
        <span style="color: #00af00;">return</span> v - v_bar

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">calcTestStatisticAllX</span>(y_variance_sq,sum_errors_sq,ndim,df):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Calculate the test statistic for the analysis of variance</span>
<span style="color: #cc0000;">        where the Null hypothesis is that the population A_1 -&gt; A_n</span>
<span style="color: #cc0000;">        are all equal to 0. Such that the null hypothesis gets</span>
<span style="color: #cc0000;">        rejected if any A_x != 0.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">return</span> (((y_variance_sq - sum_errors_sq) / ndim)
                / (sum_errors_sq / df))

    <span style="color: #18b2b2;">@staticmethod</span>
    <span style="color: #00af00;">def</span> <span style="color: #ef2929;">calcTestStatisticSingleX</span>(regression, s_matrix, sum_errors_sq, n, df):
        <span style="color: #cc0000;">"""</span>
<span style="color: #cc0000;">        Calculate the test statistic for the analysis of variance</span>
<span style="color: #cc0000;">        where the Null hypothesis is that the population A_n is 0.</span>
<span style="color: #cc0000;">        Such that the null hypothesis gets rejected if A_n != 0.</span>
<span style="color: #cc0000;">        """</span>
        <span style="color: #00af00;">return</span> (regression[n]**2 / s_matrix[n,n]) / (sum_errors_sq / df)
</pre>
</div>
</div>
</div>

<div id="outline-container-orgbb4eaf1" class="outline-4">
<h4 id="orgbb4eaf1"><span class="section-number-4">1.4.4</span> antelope data</h4>
<div class="outline-text-4" id="text-1-4-4">
<p>
The example data has been adapted from the Thunder Basin Antelope study found <a href="https://college.cengage.com/mathematics/brase/understandable_statistics/7e/students/datasets/mlr/frames/frame.html">online here</a>.
</p>

<p>
<a href="antelopestudy.csv"><code>antelopestudy.csv</code></a> (Our input data)
</p>

<div class="org-src-container">
<pre class="src src-txt">Spring fawn count/100,Annual precipitation(inches),Winter severity index(1=mild;5=severe),Size of adult antelope population/100
2.900000095,13.19999981,2,9.199999809
2.400000095,11.5,3,8.699999809
2,10.80000019,4,7.199999809
2.299999952,12.30000019,2,8.5
3.200000048,12.60000038,3,9.6
1.899999976,10.60000038,5,6.800000191
3.400000095,14.10000038,1,9.699999809
2.099999905,11.19999981,3,7.900000095
</pre>
</div>

<p>
<a href="antelope_predict.csv"><code>antelope_predict.csv</code></a> (Sample data used to predict new values)
</p>

<div class="org-src-container">
<pre class="src src-txt">spring fawn count/100,annual precipitation(inches),winter severity index(1=mild;5=severe),size of adult antelope population/100
2.5,14.0,3
</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="date">Created: 2018-11-21 Wed 09:02</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
